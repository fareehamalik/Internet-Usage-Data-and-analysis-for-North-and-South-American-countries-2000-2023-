filter(name %in% north_south_countries)
#print(north_south_countries)
#merging filtered dataset with the geographic data
data_map <- merge(world_map_filtered, data_sorted_united, by.x = "name", by.y= "Country Name", all.x = TRUE)
#debugging check for name difference between data_sorted_unite set and natural earth set
#setdiff(data_sorted_united$`Country Name`, world_map$name)
#print(unique(world_map$name)) #output the existing country names in the natural earth set
#debugging
#print(data_sorted_united)
print(data_sorted_united)
subset(data_sorted_united, `Country Name` == "United States of America")
# Check the 2000 value for USA
#usa_2000_value <- data_map[data_map$name == "United States of America", ]
#print(usa_2000_value)
#creating choropleth map
ggplot(data = data_map)+
geom_sf(aes(fill = `2023_clean`)) +
scale_fill_gradient(low = "lightpink", high="red", limits = c(0,100)) +
theme_minimal()+
labs(title = "Internet Usage in North and South America in 2023", fill = "Internet Usage (%)",
x = "Longitude", #x axis label
y = "Latitude" #y axis label
)+
geom_text( data = st_centroid(data_map),
aes(x=st_coordinates(geometry)[, 1], y= st_coordinates(geometry)[,2],label = name),
size=2, color="black", check_overlap = TRUE, hjust=0.5, vjust =0.5)+
coord_sf(xlim = c(-170, -30), ylim = c(-60, 90))
#manually adding USA data
usa_internet_usage_2000 <- 43.0792
#update 2000 value of usa into data map
data_map$`2000_clean`[data_map$name == "United States of America"] <- usa_internet_usage_2000
#creating choropleth map
ggplot(data = data_map)+
geom_sf(aes(fill = `2000_clean`)) +
scale_fill_gradient(low = "lightblue", high="darkblue", limits = c(0,100)) +
theme_minimal()+
labs(title = "Internet Usage in North and South America in 2000", fill = "Internet Usage (%)",
x = "Longitude", #x axis label
y = "Latitude" #y axis label
)+
geom_text( data = st_centroid(data_map),
aes(x=st_coordinates(geometry)[, 1], y= st_coordinates(geometry)[,2],label = name),
size=1, color="black", check_overlap = TRUE, hjust=0.5, vjust =0.5)+
coord_sf(xlim = c(-170, -30), ylim = c(-60, 90))
#TESTS
# Check if United States is in the merged data (kept having no coloring of map)
#subset(data_map, name == "United States of America")
setdiff(data_sorted_united$`Country Name`, world_map$name)
# Check if USA is in the dataset before merging
#subset(data_sorted_united, `Country Name` == "United States of America")
#SANKEY graph
#install.packages("networkD3")
library(networkD3)
library(htmltools)
#categorizing countries in below and above 50% usage from 2000 to 2023
data_sorted_united <- data_sorted_united %>%
mutate(
usage_2000 = ifelse(`2000_clean`< 50 ,paste(`Country Name`,"Below 50% usage"), paste(`Country Name`, "Above 50% usage") ),
usage_2023 = ifelse(`2023_clean` < 50 ,paste(`Country Name`,"Below 50% usage"), paste(`Country Name`, "Above 50% usage") )
)
#transtion data creationg
transition_data <- data_sorted_united %>%
mutate (
source = usage_2000,
target = usage_2023
) %>%
count(source, target, name="value")
#creating node list with country and usage categories
nodes <- data.frame(name=unique(c(
transition_data$source,
transition_data$target
#data_sorted_united$`Country Name`
)))
#creating links to match node
transition_data <- transition_data   %>%
mutate(
#maping source and target to node indices
source_id = match(source, nodes$name)-1,
target_id = match(target, nodes$name)-1,
value = value #every link is one country
)
#checking for NA values in source or target
sum(is.na(transition_data$source))
sum(is.na(transition_data$target))
#filtering for rows so no NAs in data
transition_data <- transition_data %>%
filter(!is.na(source)&!is.na(target))
#create sankey graph
sankeyNetwork(Links = transition_data,
Nodes= nodes,
Source="source_id",
Target ="target_id",
Value ="value",
NodeID = "name",
fontSize = 15,
nodeWidth = 30,
width = 1200,
height =800,
nodePadding = 30,
)
#troubleshooting issues
#issue was NodeId instead of NodeID
print(nodes)
#print(data_sorted_united)
#sum(is.na(data_sorted_united$source))
#sum(is.na(data_sorted_united$target))
print(transition_data)
#sum(transition_data$value)
sum(is.na(data_sorted_united$`2000_clean`))
sum(is.na(data_sorted_united$`2023_clean`))
# No longer needed code
#creaing table with transitioning of countries between usage categories
#transition_data <- data_sorted_united %>%
#count(usage_2000, usage_2023)
#including country names for better visualization
#country_labels <- paste(transition_data$usage_2000, #transition_data$usage_2023, sep = " -> ")
#adding country names to labels
#nodes$name <- unique (c(nodes$name, data_sorted_united$`Country Name`))
library(scales)
#bar chart - showing top 10 north and south american countries with highest internet usage in 2000 to 2023
#calculating increase in internet usage
increase_usage <- data_sorted_united %>%
mutate(change = `2023_clean`-`2000_clean`) %>% #compute change
arrange(desc(change)) %>% #ordering countries by greatest increase
slice_head(n=10) %>% #keeping top 10 results
pull(`Country Name`) #extracting country name
#using stacked to handle missing data and show internet usage over years
data_long <- data_sorted_united %>% #converting data to long for easy plotting
pivot_longer(cols = starts_with("20"),
names_to ="Year",
values_to = "Internet_Usage"
) %>%
mutate(Year = as.integer(parse_number(Year))) #converting to column numeric
#handling missing values existing in some years by converting NA to 0 for displaying
data_long$Internet_Usage[is.na(data_long$Internet_Usage)] <- 0
#filtering for only the top 10 North or South american countries based on their 2023 usage
data_long_top_n_s_change <- data_long %>%
filter(`Country Name` %in% increase_usage)
#normalizing internet usage percentage for better visualization
data_long_top_n_s_change <- data_long_top_n_s_change  %>%
group_by(Year) %>%
mutate(Internet_Usage = Internet_Usage/sum(Internet_Usage))
#creating the stacked bar chart
ggplot(data_long_top_n_s_change, aes(x=Year, y = Internet_Usage, fill = `Country Name`))+
geom_bar(stat="identity", position="stack", na.rm=TRUE)+
scale_x_continuous(breaks = seq(2000, 2023, 1))+
scale_y_continuous(labels = label_percent()) +
labs(title="Internet Usage Over Time (2000-2023) in North and South America", x="Year (2000-2023)", y="Internet Usage (%)", fill = "Country") +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, margin = margin(b=20)), #centering title
axis.text.x = element_text(angle = 45, hjust = 1) #rotating x axis for readability
)
#pie chart to show internet usage across countries (grouping them)
#calc avg internet usage over the years 2000  - 2023 to handle NA
data_sorted_united <- data_sorted_united %>%
mutate(`Average Internet Usage`= rowMeans(select(., starts_with("20")), na.rm=TRUE)/100)
#creating usage groups by dividing per cent to 3 categories (Low, medium and high)
data_sorted_united <- data_sorted_united  %>%
mutate(usage_group = case_when(
is.na(`Average Internet Usage`) ~ "NA", #for NA values
`Average Internet Usage` <= 0.33 ~ "Low Usage", #0% to #33%
`Average Internet Usage` > 0.33 & `Average Internet Usage` <= 0.66 ~ "Medium Usage", #33% to #66%
`Average Internet Usage` > 0.66 ~ "High Usage" #66% to #100%
))
#checking dist of usage groups
table(data_sorted_united$usage_group)
#Counting number of countries in North and South per usage group
usage_counts <- data_sorted_united  %>%
group_by(usage_group) %>%
summarise(count = n())
#Create pie chart
ggplot(usage_counts, aes(x = "", y= count, fill=usage_group))+
geom_bar(stat = "identity", width = 1)+
coord_polar("y", start = 0)+
labs(title = "Internet Usage Groups 2000 - 2023",
x = "Usage Group",
y = "Number of North and South American Countries",
fill =  "Usage Category") +
scale_fill_manual(values = c("Low Usage"="red", "Medium Usage" ="lightblue", "High Usage" = "darkblue", "NA" = "grey"))
#troubleshooting
#print(data_sorted_united)
summary(data_sorted_united$`Average Internet Usage`)
#install.packages("viridis")
library(viridis)
#data_long$Internet_Usage[is.na(data_long$Internet_Usage)] <- 0
# Heatmap
ggplot(data_long, aes(x = Year, y = `Country Name`, fill = Internet_Usage)) +
geom_tile(color = "white") +
scale_fill_viridis_c(direction = 1,
breaks = seq(0, 100, by = 15)) +
scale_x_continuous(
breaks = seq(2000, 2023, by = 1), #show all years
expand = c(0,0) #remove extra space around x axis
)+
theme_minimal() +
theme(legend.position="bottom",
plot.title = element_text(size = 18, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1), #rotate x axis labels
axis.text.y = element_text(angle= 0, hjust=1, size = 5),
plot.margin = margin(10,10,10,40) #making more space for y axis
) +
labs(
title = "Internet usage by Country and Year",
x = "Year",
y = "Country",
fill = "Internet Usage"
)
#trouble shooting
summary(data_long)
sum(is.na(data_long$Internet_Usage))  # Check for missing values in Internet_Usage
unique(data_long$`Country Name`)  # Check which countries are included
print(unique(data_long$`Country Name`))  # List all countries present in the dataset
#Requirment 1
#data manipulation
#installing and loading libraries
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("ggplot2")
#install.packages("readr")
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
#loading dataset (csv)
data <- read_csv("internet_usage.csv")
#testing data is loaded correctly
#view first few rows of data
head(data)
#getting summary of dataset
summary(data)
#debugging checking the datset structure
#str(data)
#manipulating and cleaning data (making year columns numeric and handling missing values)
data_clean <- data %>%
mutate(across(starts_with("20"),
~na_if(., ".."),
.names = "{.col}_clean")) %>%
mutate(across(starts_with("20"),
~as.numeric(.)))
#debugging checking for conversion
#summary(data_clean)
#str(data_clean)
#removing the original columns before cleaning
data_cleaned <- data_clean %>%
select(-one_of(as.character(2000:2023)))
#check result
#checking for conversion
summary(data_cleaned)
str(data_cleaned) #checking cleaned data
#creating vector for North and South American Countries
north_south_countries <- c(
"American Samoa", "Bahamas", "Barbados", "Belize", "Canada", "Cayman Is.",
"Costa Rica", "Cuba", "Dominican Rep.", "El Salvador", "Grenada", "Guatemala",
"Haiti", "Honduras", "Jamaica", "Mexico", "Nicaragua", "Panama", "Puerto Rico",
"Trinidad and Tobago", "United States of America", "U.S. Virgin Is.", "Argentina",
"Bolivia", "Brazil", "Chile", "Colombia", "Ecuador", "Guyana", "Paraguay", "Peru",
"Suriname", "Uruguay", "Venezuela"
)
#filtering to only keep north and south american countries
data_american <- data_cleaned %>%
filter(`Country Name` %in% north_south_countries)
#summary(data_american)
head(data_american)
#arranging the rows so that country with highest data in 2023 is displayes first
data_sorted <- data_american %>%
arrange(desc(`2023_clean`))
#using tidyr to combine columns
data_sorted_united <- data_sorted  %>%
unite(`Country Information`, `Country Name`, `Country Code`, sep = " (", remove = TRUE, na.rm = FALSE) %>%
mutate(`Country Information` = paste0(`Country Information`,")"))
#testing
#head(data_sorted)
#print(colnames(data_american))
#print(colnames(data_cleaned))
#head(data_sorted, 3)
head(data_sorted_united)
#install.packages("sf")
#install.packages("rnaturalearth")
#install.packages("rnaturalearthdata")
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
#decided to remove country codes
print(data_sorted_united)
data_sorted_united <- data_sorted_united %>%
mutate(`Country Name` = gsub("\\s*\\(.*\\)","", `Country Information`))
#debugging trouble shooting
#print(unique(data_sorted_united$`Country Name`)) # Verify USA is renamed
#subset(data_map, name == "United States")
#print(unique(world_map$name))
#"United States of America" %in% world_map$name
#"United States of America" %in% world_map$name
#sum(is.na(data_sorted_united$"United States"))
#load world map data
world_map <- ne_countries(scale ="medium", returnclass = "sf")
unique(world_map$name)
#filtering for north and south america
world_map_filtered <- world_map  %>%
filter(name %in% north_south_countries)
#print(north_south_countries)
#merging filtered dataset with the geographic data
data_map <- merge(world_map_filtered, data_sorted_united, by.x = "name", by.y= "Country Name", all.x = TRUE)
#debugging check for name difference between data_sorted_unite set and natural earth set
#setdiff(data_sorted_united$`Country Name`, world_map$name)
#print(unique(world_map$name)) #output the existing country names in the natural earth set
#debugging
#print(data_sorted_united)
print(data_sorted_united)
subset(data_sorted_united, `Country Name` == "United States of America")
# Check the 2000 value for USA
#usa_2000_value <- data_map[data_map$name == "United States of America", ]
#print(usa_2000_value)
#creating choropleth map
ggplot(data = data_map)+
geom_sf(aes(fill = `2023_clean`)) +
scale_fill_gradient(low = "lightpink", high="red", limits = c(0,100)) +
theme_minimal()+
labs(title = "Internet Usage in North and South America in 2023", fill = "Internet Usage (%)",
x = "Longitude", #x axis label
y = "Latitude" #y axis label
)+
geom_text( data = st_centroid(data_map),
aes(x=st_coordinates(geometry)[, 1], y= st_coordinates(geometry)[,2],label = name),
size=2, color="black", check_overlap = TRUE, hjust=0.5, vjust =0.5)+
coord_sf(xlim = c(-170, -30), ylim = c(-60, 90))
#manually adding USA data
usa_internet_usage_2000 <- 43.0792
#update 2000 value of usa into data map
data_map$`2000_clean`[data_map$name == "United States of America"] <- usa_internet_usage_2000
#creating choropleth map
ggplot(data = data_map)+
geom_sf(aes(fill = `2000_clean`)) +
scale_fill_gradient(low = "lightblue", high="darkblue", limits = c(0,100)) +
theme_minimal()+
labs(title = "Internet Usage in North and South America in 2000", fill = "Internet Usage (%)",
x = "Longitude", #x axis label
y = "Latitude" #y axis label
)+
geom_text( data = st_centroid(data_map),
aes(x=st_coordinates(geometry)[, 1], y= st_coordinates(geometry)[,2],label = name),
size=1, color="black", check_overlap = TRUE, hjust=0.5, vjust =0.5)+
coord_sf(xlim = c(-170, -30), ylim = c(-60, 90))
#TESTS
# Check if United States is in the merged data (kept having no coloring of map)
#subset(data_map, name == "United States of America")
setdiff(data_sorted_united$`Country Name`, world_map$name)
# Check if USA is in the dataset before merging
#subset(data_sorted_united, `Country Name` == "United States of America")
#SANKEY graph
#install.packages("networkD3")
library(networkD3)
library(htmltools)
#categorizing countries in below and above 50% usage from 2000 to 2023
data_sorted_united <- data_sorted_united %>%
mutate(
usage_2000 = ifelse(`2000_clean`< 50 ,paste(`Country Name`,"Below 50% usage"), paste(`Country Name`, "Above 50% usage") ),
usage_2023 = ifelse(`2023_clean` < 50 ,paste(`Country Name`,"Below 50% usage"), paste(`Country Name`, "Above 50% usage") )
)
#transtion data creationg
transition_data <- data_sorted_united %>%
mutate (
source = usage_2000,
target = usage_2023
) %>%
count(source, target, name="value")
#creating node list with country and usage categories
nodes <- data.frame(name=unique(c(
transition_data$source,
transition_data$target
#data_sorted_united$`Country Name`
)))
#creating links to match node
transition_data <- transition_data   %>%
mutate(
#maping source and target to node indices
source_id = match(source, nodes$name)-1,
target_id = match(target, nodes$name)-1,
value = value #every link is one country
)
#checking for NA values in source or target
sum(is.na(transition_data$source))
sum(is.na(transition_data$target))
#filtering for rows so no NAs in data
transition_data <- transition_data %>%
filter(!is.na(source)&!is.na(target))
#create sankey graph
sankeyNetwork(Links = transition_data,
Nodes= nodes,
Source="source_id",
Target ="target_id",
Value ="value",
NodeID = "name",
fontSize = 15,
nodeWidth = 30,
width = 1200,
height =800,
nodePadding = 30,
)
#troubleshooting issues
#issue was NodeId instead of NodeID
print(nodes)
#print(data_sorted_united)
#sum(is.na(data_sorted_united$source))
#sum(is.na(data_sorted_united$target))
print(transition_data)
#sum(transition_data$value)
sum(is.na(data_sorted_united$`2000_clean`))
sum(is.na(data_sorted_united$`2023_clean`))
# No longer needed code
#creaing table with transitioning of countries between usage categories
#transition_data <- data_sorted_united %>%
#count(usage_2000, usage_2023)
#including country names for better visualization
#country_labels <- paste(transition_data$usage_2000, #transition_data$usage_2023, sep = " -> ")
#adding country names to labels
#nodes$name <- unique (c(nodes$name, data_sorted_united$`Country Name`))
library(scales)
#bar chart - showing top 10 north and south american countries with highest internet usage in 2000 to 2023
#calculating increase in internet usage
increase_usage <- data_sorted_united %>%
mutate(change = `2023_clean`-`2000_clean`) %>% #compute change
arrange(desc(change)) %>% #ordering countries by greatest increase
slice_head(n=10) %>% #keeping top 10 results
pull(`Country Name`) #extracting country name
#using stacked to handle missing data and show internet usage over years
data_long <- data_sorted_united %>% #converting data to long for easy plotting
pivot_longer(cols = starts_with("20"),
names_to ="Year",
values_to = "Internet_Usage"
) %>%
mutate(Year = as.integer(parse_number(Year))) #converting to column numeric
#handling missing values existing in some years by converting NA to 0 for displaying
data_long$Internet_Usage[is.na(data_long$Internet_Usage)] <- 0
#filtering for only the top 10 North or South american countries based on their 2023 usage
data_long_top_n_s_change <- data_long %>%
filter(`Country Name` %in% increase_usage)
#normalizing internet usage percentage for better visualization
data_long_top_n_s_change <- data_long_top_n_s_change  %>%
group_by(Year) %>%
mutate(Internet_Usage = Internet_Usage/sum(Internet_Usage))
#creating the stacked bar chart
ggplot(data_long_top_n_s_change, aes(x=Year, y = Internet_Usage, fill = `Country Name`))+
geom_bar(stat="identity", position="stack", na.rm=TRUE)+
scale_x_continuous(breaks = seq(2000, 2023, 1))+
scale_y_continuous(labels = label_percent()) +
labs(title="Internet Usage Over Time (2000-2023) in North and South America", x="Year (2000-2023)", y="Internet Usage (%)", fill = "Country") +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, margin = margin(b=20)), #centering title
axis.text.x = element_text(angle = 45, hjust = 1) #rotating x axis for readability
)
#pie chart to show internet usage across countries (grouping them)
#calc avg internet usage over the years 2000  - 2023 to handle NA
data_sorted_united <- data_sorted_united %>%
mutate(`Average Internet Usage`= rowMeans(select(., starts_with("20")), na.rm=TRUE)/100)
#creating usage groups by dividing per cent to 3 categories (Low, medium and high)
data_sorted_united <- data_sorted_united  %>%
mutate(usage_group = case_when(
is.na(`Average Internet Usage`) ~ "NA", #for NA values
`Average Internet Usage` <= 0.33 ~ "Low Usage", #0% to #33%
`Average Internet Usage` > 0.33 & `Average Internet Usage` <= 0.66 ~ "Medium Usage", #33% to #66%
`Average Internet Usage` > 0.66 ~ "High Usage" #66% to #100%
))
#checking dist of usage groups
table(data_sorted_united$usage_group)
#Counting number of countries in North and South per usage group
usage_counts <- data_sorted_united  %>%
group_by(usage_group) %>%
summarise(count = n())
#Create pie chart
ggplot(usage_counts, aes(x = "", y= count, fill=usage_group))+
geom_bar(stat = "identity", width = 1)+
coord_polar("y", start = 0)+
labs(title = "Internet Usage Groups 2000 - 2023",
x = "Usage Group",
y = "Number of North and South American Countries",
fill =  "Usage Category") +
scale_fill_manual(values = c("Low Usage"="red", "Medium Usage" ="lightblue", "High Usage" = "darkblue", "NA" = "grey"))
#troubleshooting
#print(data_sorted_united)
summary(data_sorted_united$`Average Internet Usage`)
#install.packages("viridis")
library(viridis)
#data_long$Internet_Usage[is.na(data_long$Internet_Usage)] <- 0
# Heatmap
ggplot(data_long, aes(x = Year, y = `Country Name`, fill = Internet_Usage)) +
geom_tile(color = "white") +
scale_fill_viridis_c(direction = 1,
breaks = seq(0, 100, by = 15)) +
scale_x_continuous(
breaks = seq(2000, 2023, by = 1), #show all years
expand = c(0,0) #remove extra space around x axis
)+
theme_minimal() +
theme(legend.position="bottom",
plot.title = element_text(size = 18, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1), #rotate x axis labels
axis.text.y = element_text(angle= 0, hjust=1, size = 5),
plot.margin = margin(10,10,10,40) #making more space for y axis
) +
labs(
title = "Internet usage by Country and Year",
x = "Year",
y = "Country",
fill = "Internet Usage"
)
#trouble shooting
summary(data_long)
sum(is.na(data_long$Internet_Usage))  # Check for missing values in Internet_Usage
unique(data_long$`Country Name`)  # Check which countries are included
print(unique(data_long$`Country Name`))  # List all countries present in the dataset
